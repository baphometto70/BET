# üìä Analisi Completa degli Script del Progetto BET

## üéØ Panoramica Generale

Il progetto implementa un **sistema completo di previsione e selezione scommesse** sul calcio, con:
- **Acquisizione dati** (partite, quote, statistiche)
- **Feature engineering** (xG, rest days, meteo, ecc.)
- **Modelli ML** (1X2 e Over/Under 2.5)
- **Selezione value bets** (edge, Kelly, confidenza)
- **Dashboard web** (Flask) per orchestrazione
- **Pipeline giornaliera** automatizzabile

---

## üìÅ Architettura del Sistema

### **Flusso Dati Principale**

```
1. fixtures_fetcher.py ‚Üí fixtures.csv
2. odds_fetcher.py ‚Üí fixtures.csv (quote)
3. features_populator.py ‚Üí features.csv
4. model_pipeline.py ‚Üí predictions.csv + report.html
5. scommesse_pipeline.py ‚Üí bets_log.csv + metrics_daily.csv
```

### **Script di Supporto**

- `historical_builder.py`: costruisce dataset storico per training
- `run_day.py`: pipeline alternativa con modello Poisson
- `sync_features_ids.py`: allinea match_id tra fixtures e features
- `sanitize_fixtures.py`: rimuove righe con overround eccessivo
- `debug.py`: diagnostica join fixtures/features
- `tools/checks.py`: validazione configurazione e CSV

---

## üîç Analisi Dettagliata per Script

### 1. **app.py** - Dashboard Flask Web

**Scopo**: Interfaccia web per eseguire pipeline senza CLI

**Punti di Forza**:
- ‚úÖ Threading per job asincroni (evita blocchi UI)
- ‚úÖ Lock per prevenire esecuzioni multiple
- ‚úÖ Logging in tempo reale (`logs/current.log`)
- ‚úÖ No-cache headers (aggiornamenti immediati)
- ‚úÖ Stato sistema (presenza modelli, storico, previsioni)
- ‚úÖ Download file (report, CSV)

**Problemi Identificati**:
- ‚ö†Ô∏è **Secret key hardcoded** (`"dev-local-only"`) ‚Üí vulnerabilit√† in produzione
- ‚ö†Ô∏è **Nessuna autenticazione** ‚Üí accesso aperto a chiunque
- ‚ö†Ô∏è **Thread daemon** ‚Üí potrebbero terminare prima del completamento
- ‚ö†Ô∏è **Nessun timeout** sui subprocess ‚Üí rischio hang
- ‚ö†Ô∏è **Gestione errori limitata** ‚Üí crash possibili

**Miglioramenti Consigliati**:
```python
# 1. Secret key da env
APP.secret_key = os.getenv("FLASK_SECRET_KEY", secrets.token_hex(32))

# 2. Autenticazione base
from functools import wraps
def require_auth(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        auth = request.authorization
        if not auth or auth.password != os.getenv("DASH_PASSWORD"):
            return Response('Login richiesto', 401, {'WWW-Authenticate': 'Basic realm="Login"'})
        return f(*args, **kwargs)
    return decorated

# 3. Timeout subprocess
proc = subprocess.run(..., timeout=3600)  # 1h max

# 4. Thread non-daemon o join
t = threading.Thread(..., daemon=False)
t.start()
t.join(timeout=3600)
```

---

### 2. **fixtures_fetcher.py** - Recupero Partite

**Scopo**: Scarica partite future da football-data.org (fallback TheOddsAPI)

**Punti di Forza**:
- ‚úÖ Doppia fonte (FD + TOA) con fallback automatico
- ‚úÖ Gestione rate limit (429) con retry intelligente
- ‚úÖ Normalizzazione nomi squadre (unidecode)
- ‚úÖ Filtro partite finite/rinviate
- ‚úÖ Match ID stabile e univoco

**Problemi Identificati**:
- ‚ö†Ô∏è **Token hardcoded** in `read_cfg()` ‚Üí leggere solo da env/config
- ‚ö†Ô∏è **Nessun retry su errori di rete** ‚Üí fallisce su timeout/interruzioni
- ‚ö†Ô∏è **Match ID fragile** ‚Üí dipende da nomi squadre (variazioni ‚Üí duplicati)
- ‚ö†Ô∏è **Nessun logging strutturato** ‚Üí solo print

**Miglioramenti Consigliati**:
```python
# 1. Retry decorator
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
def fd_get(path, params=None, token=""):
    # ...

# 2. Match ID pi√π robusto (usa ID API se disponibile)
match_id = f"{date_str}_{m.get('id', '')}_{comp_code}"

# 3. Logging strutturato
import logging
logger = logging.getLogger(__name__)
logger.info(f"[FD] {code}: trovate {len(rows)} partite.")
```

---

### 3. **features_populator.py** - Popolamento Features

**Scopo**: Estrae statistiche (xG, rest days) da Understat (scraping + cache)

**Punti di Forza**:
- ‚úÖ **Auto-learning nomi squadre** (`team_map.json`) ‚Üí migliora nel tempo
- ‚úÖ **Cache HTML locale** ‚Üí evita richieste ripetute
- ‚úÖ **Fuzzy matching** con `rapidfuzz` ‚Üí robusto a variazioni nomi
- ‚úÖ **Refresh elenco leghe** ‚Üí aggiorna mapping squadre
- ‚úÖ **Meteo flag** (Open-Meteo) ‚Üí feature aggiuntiva
- ‚úÖ **Gestione encoding** (unicode, ascii clean)

**Problemi Identificati**:
- ‚ö†Ô∏è **Scraping fragile** ‚Üí regex su HTML pu√≤ rompersi se Understat cambia formato
- ‚ö†Ô∏è **Nessun rate limiting avanzato** ‚Üí rischio ban IP
- ‚ö†Ô∏è **Cache senza TTL** ‚Üí dati vecchi se stagione cambia
- ‚ö†Ô∏è **Meteo solo per stadi hardcoded** ‚Üí copertura limitata
- ‚ö†Ô∏è **Nessuna gestione errori parsing JSON** ‚Üí crash silenziosi

**Miglioramenti Consigliati**:
```python
# 1. TTL cache
def _cache_path(team: str, date_iso: str) -> Path:
    p = CACHE_DIR / f"{safe}_{season}.html"
    if p.exists():
        age = time.time() - p.stat().st_mtime
        if age > 86400 * 7:  # 7 giorni
            p.unlink()  # ricarica
    return p

# 2. Rate limiting con backoff
from time import sleep
import random

def safe_request(url, delay=0.6):
    sleep(delay + random.uniform(0, 0.3))  # jitter
    return requests.get(url, headers=UA, timeout=30)

# 3. Validazione JSON estratti
def _extract_json_from_understat(html: str, varname: str) -> Optional[list]:
    # ... parsing ...
    if data and isinstance(data, list) and len(data) > 0:
        # valida struttura
        if all('xG' in m and 'xGA' in m for m in data[:5]):
            return data
    return None
```

---

### 4. **odds_fetcher.py** - Recupero Quote

**Scopo**: Aggiorna quote 1X2 e O/U 2.5 da TheOddsAPI

**Punti di Forza**:
- ‚úÖ **Normalizzazione nomi** robusta (alias, rimozione suffissi)
- ‚úÖ **Best price** (max tra bookmaker) ‚Üí quote migliori
- ‚úÖ **Whitelist bookmaker** (config.toml) ‚Üí filtra fonti
- ‚úÖ **Match simmetrico** (home/away invertiti) ‚Üí pi√π robusto

**Problemi Identificati**:
- ‚ö†Ô∏è **Nessun retry su errori API** ‚Üí fallisce su 429/timeout
- ‚ö†Ô∏è **Alias hardcoded** ‚Üí limitato a poche squadre
- ‚ö†Ô∏è **Nessun logging match non trovati** ‚Üí difficile debug
- ‚ö†Ô∏è **Overwrite completo fixtures.csv** ‚Üí perde altre colonne se presenti

**Miglioramenti Consigliati**:
```python
# 1. Retry con backoff
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential())
def fetch_odds(sport, params):
    # ...

# 2. Merge incrementale (non overwrite)
df_old = pd.read_csv(FX)
df_new = df_old.copy()
# aggiorna solo colonne quote
for col in ["odds_1", "odds_x", "odds_2", ...]:
    df_new[col] = df_new[col].combine_first(df_updates[col])
df_new.to_csv(FX, index=False)

# 3. Logging match non trovati
if not found:
    logger.warning(f"[MISS] {row['home']} vs {row['away']} - nessun match in TOA")
```

---

### 5. **model_pipeline.py** - Pipeline ML

**Scopo**: Addestra modelli (OU 2.5, 1X2) e genera previsioni

**Punti di Forza**:
- ‚úÖ **STRICT_ML** ‚Üí probabilit√† solo da modelli (non da quote)
- ‚úÖ **Cross-validation** (StratifiedKFold) ‚Üí metriche affidabili
- ‚úÖ **Preprocessing robusto** (SimpleImputer, StandardScaler)
- ‚úÖ **Metadati modello** (feature list salvata) ‚Üí versioning
- ‚úÖ **Calcolo value/Kelly** ‚Üí selezione scommesse
- ‚úÖ **Report HTML** ‚Üí output leggibile

**Problemi Identificati**:
- ‚ö†Ô∏è **Nessun train-ou/train-1x2 di default** ‚Üí CLI confusa (solo --predict)
- ‚ö†Ô∏è **Imputazione costante (0.0)** ‚Üí perdita informazione
- ‚ö†Ô∏è **Nessuna calibrazione probabilit√†** ‚Üí probabilit√† non calibrate
- ‚ö†Ô∏è **Nessun early stopping** ‚Üí rischio overfitting
- ‚ö†Ô∏è **Feature hardcoded** ‚Üí non adattive a dataset diversi

**Miglioramenti Consigliati**:
```python
# 1. Imputazione con mediana (non zero)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="median")  # invece di "constant"

# 2. Calibrazione probabilit√†
from sklearn.calibration import CalibratedClassifierCV
clf_base = LogisticRegression(...)
clf = CalibratedClassifierCV(clf_base, method='isotonic', cv=5)

# 3. Feature selection automatica
from sklearn.feature_selection import SelectKBest, f_classif
selector = SelectKBest(f_classif, k=10)
X_selected = selector.fit_transform(X, y)

# 4. CLI pi√π chiara
ap.add_argument("--train", choices=["ou", "1x2", "both"], help="Quale modello addestrare")
```

---

### 6. **run_day.py** - Pipeline Giornaliera (Poisson)

**Scopo**: Alternativa a model_pipeline.py usando modello Poisson per previsioni

**Punti di Forza**:
- ‚úÖ **Modello Poisson** ‚Üí semplice e interpretabile
- ‚úÖ **Statistiche reali** (ultime N partite) ‚Üí dati freschi
- ‚úÖ **Multi-mercato** (1X2, O/U, BTTS, DC, DNB, CS) ‚Üí copertura completa
- ‚úÖ **Home advantage dinamico** ‚Üí adattato per competizione
- ‚úÖ **Output tabellare** ‚Üí leggibile a console
- ‚úÖ **Append mode** ‚Üí non sovrascrive storico

**Problemi Identificati**:
- ‚ö†Ô∏è **Modello Poisson semplice** ‚Üí non cattura correlazioni complesse
- ‚ö†Ô∏è **Nessuna validazione** ‚Üí probabilit√† non testate
- ‚ö†Ô∏è **Cache team senza TTL** ‚Üí dati vecchi
- ‚ö†Ô∏è **Nessun fallback se API fallisce** ‚Üí pipeline interrotta
- ‚ö†Ô∏è **Pick euristici** (soglie hardcoded) ‚Üí non ottimizzati

**Miglioramenti Consigliati**:
```python
# 1. Poisson bivariato (correlazione goal)
from scipy.stats import poisson
# modello pi√π sofisticato con correlazione

# 2. Validazione backtest
def backtest_poisson(historical_data):
    # testa accuratezza su dati passati
    pass

# 3. Pick basati su value (non solo probabilit√†)
def pick_with_value(p1, px, p2, odds1, oddsx, odds2):
    ev1 = (p1 * odds1) - 1
    evx = (px * oddsx) - 1
    ev2 = (p2 * odds2) - 1
    return max([("1", ev1), ("X", evx), ("2", ev2)], key=lambda x: x[1])
```

---

### 7. **historical_builder.py** - Costruzione Dataset Storico

**Scopo**: Costruisce `data/historical_dataset.csv` per training ML

**Punti di Forza**:
- ‚úÖ **Fonte gratuita** (football-data.co.uk) ‚Üí CSV pubblici
- ‚úÖ **Quote closing** (AvgH/AvgD/AvgA) ‚Üí dati reali di mercato
- ‚úÖ **Target derivati** (OU 2.5, BTTS, 1X2) ‚Üí automatici da gol
- ‚úÖ **Feature da Understat** ‚Üí xG, rest days
- ‚úÖ **Gestione multi-stagione** ‚Üí copre range temporali ampi

**Problemi Identificati**:
- ‚ö†Ô∏è **Parsing date fragile** ‚Üí formato variabile (`%d/%m/%y` vs `%d/%m/%Y`)
- ‚ö†Ô∏è **Nessuna validazione quote** ‚Üí possibili errori di parsing
- ‚ö†Ô∏è **Scraping Understat lento** ‚Üí richiede molto tempo
- ‚ö†Ô∏è **Nessun checkpoint** ‚Üí se fallisce, ricomincia da zero
- ‚ö†Ô∏è **Target 1X2 codificato male** ‚Üí `0/1/2` invece di `'1'/'X'/'2'`

**Miglioramenti Consigliati**:
```python
# 1. Checkpoint incrementale
def build_historical_incremental(date_from, date_to, ...):
    existing = pd.read_csv(OUT_CSV) if OUT_CSV.exists() else pd.DataFrame()
    processed_dates = set(existing["date"].unique()) if not existing.empty else set()
    
    for date in date_range(date_from, date_to):
        if date in processed_dates:
            continue  # skip gi√† processato
        # processa solo date mancanti

# 2. Target 1X2 corretto
base["target_1x2"] = pd.Series("", index=base.index)
base.loc[base["ft_home_goals"] > base["ft_away_goals"], "target_1x2"] = "1"
base.loc[base["ft_home_goals"] == base["ft_away_goals"], "target_1x2"] = "X"
base.loc[base["ft_home_goals"] < base["ft_away_goals"], "target_1x2"] = "2"

# 3. Validazione quote
def validate_odds(o1, ox, o2):
    if any(pd.isna([o1, ox, o2])):
        return False
    or_ = (1/o1 + 1/ox + 1/o2) - 1
    return 0.02 <= or_ <= 0.15  # overround ragionevole
```

---

### 8. **scommesse_pipeline.py** - Selezione Value Bets

**Scopo**: Calcola edge, seleziona scommesse, applica Kelly, logga risultati

**Punti di Forza**:
- ‚úÖ **Blending modello/mercato** (Œª configurabile) ‚Üí bilancia fonti
- ‚úÖ **Multi-mercato** (1X2, DC, DNB, O/U) ‚Üí copertura completa
- ‚úÖ **Kelly frazionato** ‚Üí staking ottimale
- ‚úÖ **Confidenza bands** (A/B/C) ‚Üí filtraggio qualit√†
- ‚úÖ **Logging scommesse** ‚Üí tracciamento ROI
- ‚úÖ **Metriche aggregate** ‚Üí monitoraggio performance

**Problemi Identificati**:
- ‚ö†Ô∏è **Blending semplice** ‚Üí non ottimale (media pesata lineare)
- ‚ö†Ô∏è **Edge calcolato male** ‚Üí `p - p_mkt` non considera overround
- ‚ö†Ô∏è **Nessuna gestione quote mancanti** ‚Üí crash su NaN
- ‚ö†Ô∏è **Kelly senza validazione** ‚Üí pu√≤ suggerire stake > 100%
- ‚ö†Ô∏è **Metriche incomplete** ‚Üí Brier/logloss sempre NaN

**Miglioramenti Consigliati**:
```python
# 1. Edge corretto (considera overround)
def edge_corrected(p_model, p_market, overround):
    # p_market gi√† include overround, ma va normalizzata
    p_market_adj = p_market / (1 + overround)
    return p_model - p_market_adj

# 2. Blending bayesiano (non lineare)
def blend_bayesian(p_model, p_market, confidence_model):
    # usa confidence come peso dinamico
    w = confidence_model / (confidence_model + 0.1)  # 0.1 = incertezza mercato
    return w * p_model + (1 - w) * p_market

# 3. Kelly con cap
def kelly_safe(p, odds, max_stake=0.25):
    k = kelly_fraction(p, odds)
    return min(k, max_stake)  # max 25% bankroll

# 4. Metriche reali
def compute_brier(y_true, y_pred):
    from sklearn.metrics import brier_score_loss
    return brier_score_loss(y_true, y_pred)
```

---

### 9. **sync_features_ids.py** - Sincronizzazione ID

**Scopo**: Allinea `match_id` tra `fixtures.csv` e `features.csv`

**Punti di Forza**:
- ‚úÖ **Normalizzazione robusta** (unidecode, alias, rimozione suffissi)
- ‚úÖ **Join su (date, home, away)** ‚Üí robusto a variazioni ID
- ‚úÖ **Backup automatico** ‚Üí sicurezza dati
- ‚úÖ **Report matchate/non matchate** ‚Üí diagnostica

**Problemi Identificati**:
- ‚ö†Ô∏è **Alias hardcoded** ‚Üí limitato
- ‚ö†Ô∏è **Nessuna gestione duplicati** ‚Üí pu√≤ creare conflitti
- ‚ö†Ô∏è **Overwrite completo** ‚Üí perde righe non matchate

**Miglioramenti Consigliati**:
```python
# 1. Conserva righe non matchate (append, non overwrite)
out = pd.concat([matched, unmatched_features], ignore_index=True)

# 2. Gestione duplicati
out = out.drop_duplicates(subset=["match_id"], keep="last")

# 3. Alias da file esterno
ALIAS_FILE = Path("data/team_aliases.json")
if ALIAS_FILE.exists():
    aliases.update(json.loads(ALIAS_FILE.read_text()))
```

---

### 10. **sanitize_fixtures.py** - Sanitizzazione

**Scopo**: Rimuove righe con overround eccessivo (quote sospette)

**Punti di Forza**:
- ‚úÖ **Filtro overround** ‚Üí rimuove quote errate
- ‚úÖ **Configurabile** (config.toml) ‚Üí soglia personalizzabile

**Problemi Identificati**:
- ‚ö†Ô∏è **Nessun backup** ‚Üí perde dati senza possibilit√† di recupero
- ‚ö†Ô∏è **Overround solo 1X2** ‚Üí non valida O/U
- ‚ö†Ô∏è **Nessun logging** ‚Üí non sa quali righe sono state rimosse

**Miglioramenti Consigliati**:
```python
# 1. Backup prima di rimuovere
backup_path = FX.with_suffix(f".bak_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
shutil.copy2(FX, backup_path)

# 2. Validazione O/U
def overround_ou(odds_over, odds_under):
    return (1/odds_over + 1/odds_under) - 1

# 3. Logging righe rimosse
removed = df[~keep]
if not removed.empty:
    logger.warning(f"Rimosse {len(removed)} righe con overround eccessivo")
    removed.to_csv(FX.with_suffix(".removed.csv"), index=False)
```

---

### 11. **debug.py** - Diagnostica

**Scopo**: Analizza join tra fixtures e features

**Punti di Forza**:
- ‚úÖ **Report dettagliato** ‚Üí mostra mismatch
- ‚úÖ **File di debug** ‚Üí facilita troubleshooting

**Problemi Identificati**:
- ‚ö†Ô∏è **Nessuna azione correttiva** ‚Üí solo diagnostica

**Miglioramenti Consigliati**:
```python
# Aggiungi opzione --fix per chiamare sync_features_ids.py automaticamente
if args.fix:
    subprocess.run(["python", "sync_features_ids.py"])
```

---

### 12. **tools/checks.py** - Validazione

**Scopo**: Verifica configurazione e completezza CSV

**Punti di Forza**:
- ‚úÖ **Check multipli** (config, fixtures, odds, features)
- ‚úÖ **Exit codes** ‚Üí integrabile in script

**Problemi Identificati**:
- ‚ö†Ô∏è **Check features troppo rigido** ‚Üí richiede TUTTE le colonne piene
- ‚ö†Ô∏è **Nessun check su predictions.csv** ‚Üí non valida output modello

**Miglioramenti Consigliati**:
```python
# 1. Check features pi√π flessibile (almeno 80% piene)
def check_features(date_str: str) -> int:
    # ...
    filled_pct = (m[feat_cols].notna().sum(axis=1) / len(feat_cols)).mean()
    return 0 if filled_pct >= 0.8 else 1

# 2. Check predictions
def check_predictions() -> int:
    pred = pd.read_csv("predictions.csv")
    required = ["p1", "px", "p2", "p_over_2_5", "p_under_2_5"]
    return 0 if all(c in pred.columns for c in required) else 1
```

---

## üîß Problemi Architetturali Globali

### 1. **Gestione Errori Inconsistente**
- Alcuni script usano `try/except` generici, altri no
- Nessun logging strutturato (solo `print`)
- **Soluzione**: Introdurre `logging` module ovunque

### 2. **Configurazione Sparsa**
- `config.toml` (API keys)
- `config.json` (soglie, staking)
- Hardcoded in alcuni script
- **Soluzione**: Centralizzare in `config.toml` unico

### 3. **Match ID Fragile**
- Dipende da nomi squadre (variazioni ‚Üí duplicati)
- Nessun ID stabile da API
- **Soluzione**: Usare ID API quando disponibile, fallback a hash

### 4. **Nessun Versioning Dati**
- CSV sovrascritti senza storico
- Nessun tracking di versioni dataset
- **Soluzione**: Database (SQLite) o sistema di versioning

### 5. **Testing Assente**
- Nessun test unitario
- Nessun test di integrazione
- **Soluzione**: Aggiungere pytest per funzioni critiche

---

## ‚úÖ Raccomandazioni Prioritarie

### **Alta Priorit√†** (Blocca produzione)

1. **Sicurezza Dashboard** (`app.py`)
   - Autenticazione base HTTP
   - Secret key da env
   - Rate limiting

2. **Robustezza API Calls**
   - Retry con backoff esponenziale
   - Timeout configurabili
   - Gestione errori di rete

3. **Validazione Dati**
   - Schema validation (pydantic/voluptuous)
   - Check completeness prima di training
   - Validazione quote (overround ragionevole)

### **Media Priorit√†** (Migliora qualit√†)

4. **Logging Strutturato**
   - Sostituire `print` con `logging`
   - Livelli appropriati (INFO/WARN/ERROR)
   - Rotazione log files

5. **Cache Intelligente**
   - TTL per cache HTML
   - Invalidation su cambio stagione
   - Compressione cache vecchia

6. **Calibrazione Modelli**
   - `CalibratedClassifierCV` per probabilit√† accurate
   - Validazione su holdout set
   - Metriche di calibrazione (reliability diagram)

### **Bassa Priorit√†** (Nice to have)

7. **Database invece di CSV**
   - SQLite per storico
   - Query pi√π efficienti
   - Versioning automatico

8. **Testing**
   - Unit test per funzioni critiche
   - Integration test per pipeline
   - Mock API responses

9. **Documentazione**
   - Docstring complete
   - Esempi d'uso
   - Diagrammi di flusso

---

## üìà Metriche di Qualit√† Codice

| Script | Righe | Complessit√† | Test Coverage | Documentazione |
|--------|-------|------------|---------------|----------------|
| app.py | 302 | Media | 0% | Buona |
| fixtures_fetcher.py | 214 | Bassa | 0% | Media |
| features_populator.py | 701 | Alta | 0% | Eccellente |
| odds_fetcher.py | 158 | Bassa | 0% | Scarsa |
| model_pipeline.py | 519 | Alta | 0% | Buona |
| run_day.py | 713 | Alta | 0% | Buona |
| historical_builder.py | 698 | Alta | 0% | Buona |
| scommesse_pipeline.py | 259 | Media | 0% | Scarsa |

**Media Complessit√†**: Alta (molti script >500 righe, logica complessa)

---

## üéØ Conclusioni

Il progetto √® **ben strutturato** e mostra una comprensione solida del dominio (scommesse calcio). Gli script principali sono funzionali e coprono il flusso end-to-end.

**Punti di Eccellenza**:
- ‚úÖ Auto-learning nomi squadre (`features_populator.py`)
- ‚úÖ Multi-fonte dati (FD, TOA, Understat)
- ‚úÖ Pipeline completa (dati ‚Üí previsioni ‚Üí selezione)
- ‚úÖ Dashboard web funzionale

**Aree di Miglioramento Critiche**:
- ‚ö†Ô∏è Sicurezza (autenticazione, secret keys)
- ‚ö†Ô∏è Robustezza (retry, timeout, error handling)
- ‚ö†Ô∏è Testing (0% coverage)
- ‚ö†Ô∏è Calibrazione modelli (probabilit√† non calibrate)

**Prossimi Passi Consigliati**:
1. Implementare autenticazione dashboard
2. Aggiungere retry/backoff a tutte le chiamate API
3. Introdurre logging strutturato
4. Calibrare modelli ML
5. Aggiungere test base per funzioni critiche

---

*Analisi generata il: 2025-01-XX*
*Versione progetto analizzata: corrente (tutti gli script nella root)*

